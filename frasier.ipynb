{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frasier Text Analysis\n",
    "\n",
    "I recently stumbled on [this post](https://www.reddit.com/r/dataisbeautiful/comments/8a4gbr/the_office_characters_most_distinguishing_words_oc/) on /r/dataisbeautiful. I'm a big _Frasier_ fan, so I was determined to do similar analysis, but for _Frasier_ characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the dialogue\n",
    "\n",
    "Luckily for me, there's a magnificent site [here](http://www.kacl780.net/frasier/transcripts/) which has transcripts of ALL the _Frasier_ episodes! First, let's get the links to all the episodes from the [home page](http://www.kacl780.net/frasier/transcripts/). We use BeautifulSoup to get the HTML as a nested data structure, and pull all the links that have \"episode\" in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1 transcript URL: http://www.kacl780.net/frasier/transcripts/season_1/episode_1/the_good_son.html\n",
      "number of episodes: 264\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def url_to_soup(url):\n",
    "    fp = urllib.request.urlopen(url)\n",
    "    html_str = fp.read()\n",
    "    fp.close()\n",
    "    return BeautifulSoup(html_str, 'html.parser') \n",
    "\n",
    "main_page_soup = url_to_soup(\"http://www.kacl780.net/frasier/transcripts/\")\n",
    "urls = [a.get('href') for a in main_page_soup.find_all('a')]\n",
    "urls = ['http://www.kacl780.net' + u for u in urls if 'episode' in u]\n",
    "\n",
    "print('ep 1 transcript URL: ' + urls[0])\n",
    "print('number of episodes: ' + str(len(urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's parse out the dialogue from each of the transcripts. \n",
    "\n",
    "The transcript is formatted such that each character's lines are prefaced by their name in __bold__. I thus find all the elements with tag 'b', and get all the text in between. Of course, there is some bolded text that isn't a character's lines, but that will be filtered out later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "539\n",
      "defaultdict(<class 'int'>, {'daphne': 14, 'frasier': 85, 'martin': 47, 'roz': 9, 'niles': 10}) defaultdict(<class 'int'>, {'daphne': 319, 'frasier': 1530, 'martin': 536, 'roz': 146, 'niles': 132})\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# given a string S:\n",
    "# (1) remove all punctuation\n",
    "# (2) strip trailing whitespace\n",
    "# (3) lowercase all the letters \n",
    "def clean_string(S):\n",
    "    return re.sub('['+punctuation+']', '', S).strip().lower()\n",
    "\n",
    "main_characters = set(['frasier', 'niles', 'martin', 'roz', 'daphne'])\n",
    "d_num_lines = defaultdict(int)\n",
    "d_num_words = defaultdict(int)\n",
    "d_overall_word_count = defaultdict(int)\n",
    "\n",
    "# given a bold tag bt:\n",
    "# return dialogue line as list of cleaned words    \n",
    "def get_dialogue_following_bold_tag(bt):\n",
    "    if bt.string == None:\n",
    "        return []\n",
    "    words_in_line = []\n",
    "    ns = bt.next_sibling\n",
    "    while ns != None and ns.name != 'b':\n",
    "        # dialogue has no tag associated with it\n",
    "        # other cues (like stage directions and tone) are italicized with tag i\n",
    "        if ns.name == None:\n",
    "            words_in_line += clean_string(ns.string).split()\n",
    "        # move onto the next sibling\n",
    "        ns = ns.next_sibling\n",
    "    return words_in_line\n",
    "\n",
    "def url_to_lines_dict(url):\n",
    "    soup = url_to_soup(url)\n",
    "    bold_tags = soup.find_all('b')\n",
    "    character_d = defaultdict(dict)\n",
    "    for bt in bold_tags:\n",
    "        if bt.string == None:\n",
    "            continue\n",
    "        character = clean_string(bt.string)\n",
    "        if character not in main_characters:\n",
    "            continue\n",
    "        words_in_line = get_dialogue_following_bold_tag(bt)\n",
    "        d_character_word_count = character_d[character]\n",
    "        for word in words_in_line:\n",
    "            d_overall_word_count[word] += 1\n",
    "            if word not in d_character_word_count:\n",
    "                d_character_word_count[word] = 0\n",
    "            d_character_word_count[word] += 1\n",
    "        character_d[character] = d_character_word_count\n",
    "        d_num_words[character] += len(words_in_line)\n",
    "        d_num_lines[character] += 1\n",
    "    return character_d\n",
    "\n",
    "d = url_to_lines_dict(urls[1])\n",
    "print(len(d['frasier']))\n",
    "print(d_num_lines, d_num_words)\n",
    "# number of times anyone says Frasier\n",
    "print(d_overall_word_count['frasier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2167\n",
      "15796\n"
     ]
    }
   ],
   "source": [
    "d = defaultdict(dict)\n",
    "for u in urls:\n",
    "    for character, word_count_d in url_to_lines_dict(u).items():\n",
    "        character_word_count_d = d[character]\n",
    "        for word, count in word_count_d.items():\n",
    "            if word not in character_word_count_d:\n",
    "                character_word_count_d[word] = 0\n",
    "            character_word_count_d[word] += count\n",
    "\n",
    "# number of times Frasier says 'Niles'\n",
    "print(d['frasier']['niles'])\n",
    "print(len(d['frasier']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'where', 'aren', 'wont', 'further', 'between', 'once', 'couldnt', 'own', 'ours', 'does', 'mustnt', 'before', 'my', 'itself', 'youll', 'they', 'such', 'until', 'won', 'being', 'hadn', 'am', 'so', 'only', 'in', 'hasnt', 'had', 'against', 'you', 'isn', 'most', 'again', 'haven', 'couldn', 'if', 'as', 'doesn', 'shan', 'both', 'have', 'then', 'all', 'youre', 'same', 'those', 'i', 'through', 'is', 'did', 'wasnt', 'doesnt', 'any', 'm', 'below', 'why', 'hasn', 'how', 'o', 'youve', 'himself', 'are', 'with', 'from', 'ma', 'your', 'nor', 've', 'will', 'shes', 'too', 'yourself', 'into', 'because', 'were', 'him', 'than', 'after', 'out', 'doing', 'mightnt', 'not', 'about', 'or', 'whom', 'these', 's', 'of', 'be', 'd', 'weren', 't', 'herself', 'shant', 'theirs', 'me', 'this', 'it', 'he', 'themselves', 'myself', 'needn', 'her', 'should', 'hadnt', 'do', 're', 'wouldn', 'been', 'down', 'over', 'shouldn', 'youd', 'while', 'arent', 'no', 'few', 'its', 'which', 'under', 'for', 'can', 'each', 'when', 'the', 'here', 'thatll', 'was', 'll', 'havent', 'a', 'we', 'there', 'an', 'wasn', 'by', 'y', 'to', 'shouldnt', 'don', 'but', 'just', 'has', 'isnt', 'now', 'off', 'wouldnt', 'dont', 'and', 'what', 'during', 'werent', 'ain', 'didnt', 'that', 'who', 'shouldve', 'up', 'on', 'very', 'other', 'our', 'she', 'more', 'mightn', 'some', 'neednt', 'mustn', 'hers', 'ourselves', 'having', 'at', 'above', 'yourselves', 'didn', 'yours', 'their', 'them', 'his'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(clean_string(sw) for sw in stopwords.words('english'))\n",
    "print(stop_words)\n",
    "\n",
    "for character, word_count_d in d.items():\n",
    "    for sw in stop_words:\n",
    "        if sw in word_count_d:\n",
    "            del word_count_d[sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647631\n",
      "56876 5012\n",
      "roz [('right', 210), ('one', 212), ('go', 217), ('really', 220), ('like', 239), ('get', 250), ('know', 406), ('well', 455), ('im', 464), ('frasier', 510)]\n",
      "97849 7966\n",
      "martin [('thats', 415), ('got', 439), ('like', 483), ('right', 507), ('get', 511), ('hey', 514), ('yeah', 652), ('im', 709), ('know', 797), ('well', 1120)]\n",
      "66500 5531\n",
      "daphne [('ill', 234), ('yes', 238), ('get', 255), ('right', 290), ('like', 313), ('know', 379), ('dr', 484), ('im', 560), ('crane', 564), ('well', 581)]\n",
      "295372 21892\n",
      "frasier [('like', 959), ('thats', 959), ('see', 1004), ('roz', 1312), ('right', 1669), ('dad', 1731), ('yes', 2093), ('niles', 2167), ('know', 2295), ('im', 2487)]\n",
      "131034 10670\n",
      "niles [('going', 434), ('one', 436), ('right', 505), ('daphne', 531), ('dad', 621), ('yes', 652), ('know', 654), ('frasier', 947), ('im', 1072), ('well', 1393)]\n"
     ]
    }
   ],
   "source": [
    "total_words = sum(d_num_words.values())\n",
    "print(total_words)\n",
    "\n",
    "for c in main_characters:\n",
    "    print(d_num_words[c], d_num_lines[c])\n",
    "    sorted_x = sorted(d[c].items(), key=lambda kv: kv[1])\n",
    "    ten_top_values = sorted_x[-10:]\n",
    "    print(c, ten_top_values)\n",
    "# can delete top values as alternative to stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roz\n",
      "62 alice\n",
      "239 like\n",
      "208 yeah\n",
      "455 well\n",
      "250 get\n",
      "510 frasier\n",
      "220 really\n",
      "464 im\n",
      "406 know\n",
      "194 hey\n",
      "--------------------\n",
      "martin\n",
      "37 ronee\n",
      "507 right\n",
      "511 get\n",
      "439 got\n",
      "483 like\n",
      "652 yeah\n",
      "797 know\n",
      "1120 well\n",
      "709 im\n",
      "514 hey\n",
      "--------------------\n",
      "daphne\n",
      "30 simon\n",
      "255 get\n",
      "313 like\n",
      "234 ill\n",
      "290 right\n",
      "560 im\n",
      "484 dr\n",
      "564 crane\n",
      "581 well\n",
      "379 know\n",
      "--------------------\n",
      "frasier\n",
      "30 ronee\n",
      "959 thats\n",
      "1312 roz\n",
      "1731 dad\n",
      "1004 see\n",
      "2093 yes\n",
      "2295 know\n",
      "2487 im\n",
      "2167 niles\n",
      "1669 right\n",
      "--------------------\n",
      "niles\n",
      "67 mel\n",
      "434 going\n",
      "652 yes\n",
      "621 dad\n",
      "654 know\n",
      "1072 im\n",
      "1393 well\n",
      "947 frasier\n",
      "531 daphne\n",
      "343 maris\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "total_lines = sum(d_num_lines.values())\n",
    "\n",
    "for c in main_characters:\n",
    "    heap = []\n",
    "    weight = d_num_words[c] / total_words\n",
    "    weight2 = d_num_lines[c] / total_lines\n",
    "    for word, count in d[c].items():\n",
    "        word_freq_perc = (count**3) * weight / d_overall_word_count[word]\n",
    "        if len(heap) < 10:\n",
    "            heapq.heappush(heap, (word_freq_perc, count, word))\n",
    "        else:\n",
    "            wfp_low, c_low, w_low = heapq.heappop(heap)\n",
    "            if wfp < word_freq_perc:\n",
    "                wfp_low, c_low, w_low = word_freq_perc, count, word\n",
    "            heapq.heappush(heap, (wfp_low, c_low, w_low))\n",
    "    print(c)\n",
    "    for elt in heap:\n",
    "        print(elt[1], elt[2])\n",
    "    print('--------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'Frasier' Characters' Most Distinguishing Words\n",
    "\n",
    "I recently stumbled on [this post](https://www.reddit.com/r/dataisbeautiful/comments/8a4gbr/the_office_characters_most_distinguishing_words_oc/) on /r/dataisbeautiful, which found the most distinguishing words of '_The Office_' characters. I am a fan of '_The Office_', but an even bigger fan of the sitcom '[_Frasier_](https://en.wikipedia.org/wiki/Frasier)', so I set out to do similar analysis for '_Frasier_' characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the dialogue\n",
    "\n",
    "Luckily for me, there's a great site [here](http://www.kacl780.net/frasier/transcripts/) which has complete transcripts of every '_Frasier_' episode. First, let's get the links to all the episodes from the [home page](http://www.kacl780.net/frasier/transcripts/). I use BeautifulSoup to get the HTML as a nested data structure, and pull all the links that have \"episode\" in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1 transcript URL: http://www.kacl780.net/frasier/transcripts/season_1/episode_1/the_good_son.html\n",
      "number of episodes: 264\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def url_to_soup(url):\n",
    "    fp = urllib.request.urlopen(url)\n",
    "    html_str = fp.read()\n",
    "    fp.close()\n",
    "    return BeautifulSoup(html_str, 'html.parser') \n",
    "\n",
    "main_page_soup = url_to_soup(\"http://www.kacl780.net/frasier/transcripts/\")\n",
    "urls = [a.get('href') for a in main_page_soup.find_all('a')]\n",
    "urls = ['http://www.kacl780.net' + u for u in urls if 'episode' in u]\n",
    "\n",
    "print('ep 1 transcript URL: ' + urls[0])\n",
    "print('number of episodes: ' + str(len(urls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the dialogue\n",
    "\n",
    "Now, let's parse out the dialogue from each of the transcripts. \n",
    "\n",
    "First, I'll define two helper functions. \n",
    "\n",
    "(1) `clean_string` will clean / normalize the words in the dialogue\n",
    "\n",
    "(2) `get_dialogue_following_bold_tag`. This requires a bit of explanation. In the transcript, each character's lines are prefaced by their name in __bold__. This function thus find all the elements with tag 'b', then cleans and stores all the text in between.\n",
    "\n",
    "There is some bolded on text on the website that isn't the start of a character line, but we will filter this out during processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import re\n",
    "\n",
    "# given a string S:\n",
    "# remove all punctuation, strip trailing whitespace, and lowercase ALL the letters \n",
    "def clean_string(S):\n",
    "    if S == None:\n",
    "        return None\n",
    "    return re.sub('['+punctuation+']', '', S).strip().lower()\n",
    "\n",
    "\n",
    "# given a bold tag bt:\n",
    "# return dialogue line as list of cleaned words    \n",
    "def get_dialogue_following_bold_tag(bt):\n",
    "    if bt == None or bt.string == None:\n",
    "        return []\n",
    "    words_in_line = []\n",
    "    ns = bt.next_sibling\n",
    "    while ns != None and ns.name != 'b':\n",
    "        # we specifically want tags with no \"name\"\n",
    "        # cues (like stage directions and intonation) are italicized with tag 'i'\n",
    "        if ns.name == None:\n",
    "            words_in_line += clean_string(ns.string).split()\n",
    "        # move onto the next sibling\n",
    "        ns = ns.next_sibling\n",
    "    return words_in_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get to the bulk of the processing. Given a URL that corresponds to an episode's transcript, `url_to_lines_dict` will return a dict of dicts. The outer dict's keys are the characters' names. The values are inner dicts: the keys are the words in the character's dialogue, and the values are the count of how many times the character says the word. We only process the dialogue of the main cast, which consists of Frasier, Niles, Roz, Daphne, and Martin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "main_characters = set(['frasier', 'niles', 'roz', 'daphne', 'martin'])\n",
    "\n",
    "# given a URL, convert it to the soup\n",
    "# then, find all the bold tags in the soup\n",
    "# for each of the bold tags, \n",
    "def url_to_lines_dict(url):\n",
    "    soup = url_to_soup(url)\n",
    "    bold_tags = soup.find_all('b')\n",
    "    # this is a two-level defaultdict, see https://stackoverflow.com/a/27809959\n",
    "    d_char_wc = defaultdict(lambda: defaultdict(int))\n",
    "    for bt in bold_tags:\n",
    "        char = clean_string(bt.string)\n",
    "        # only process the line if it's uttered by a main character\n",
    "        if char in main_characters:\n",
    "            for word in get_dialogue_following_bold_tag(bt):\n",
    "                d_char_wc[char][word] += 1\n",
    "    return d_char_wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's process the first episode to get a sense of what our data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frasier</th>\n",
       "      <th>roz</th>\n",
       "      <th>niles</th>\n",
       "      <th>martin</th>\n",
       "      <th>daphne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>63.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>50.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>43.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>42.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     frasier   roz  niles  martin  daphne\n",
       "you     63.0   8.0   19.0    17.0    15.0\n",
       "i       58.0   1.0   19.0    20.0    16.0\n",
       "the     50.0  16.0   11.0    13.0     9.0\n",
       "to      43.0   6.0   14.0     6.0     2.0\n",
       "a       42.0   4.0   10.0     8.0    10.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_char_wc = url_to_lines_dict(urls[0])\n",
    "df_char_wc = pd.DataFrame(d_char_wc)\n",
    "# display the top 5 most frequent words, sorted by the 'frasier' column\n",
    "df_char_wc.sort_values(by='frasier', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The above looks more or less reasonable. Let's go ahead and process the rest of the episodes, combining the resulting dictionaries as we go. NOTE: the below takes a few minutes :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frasier</th>\n",
       "      <th>roz</th>\n",
       "      <th>niles</th>\n",
       "      <th>martin</th>\n",
       "      <th>daphne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>10742.0</td>\n",
       "      <td>2169.0</td>\n",
       "      <td>4113.0</td>\n",
       "      <td>3844.0</td>\n",
       "      <td>2280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>9394.0</td>\n",
       "      <td>2057.0</td>\n",
       "      <td>4257.0</td>\n",
       "      <td>3023.0</td>\n",
       "      <td>2250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>7868.0</td>\n",
       "      <td>1321.0</td>\n",
       "      <td>3885.0</td>\n",
       "      <td>2678.0</td>\n",
       "      <td>1689.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>7482.0</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>1555.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>6987.0</td>\n",
       "      <td>1282.0</td>\n",
       "      <td>2927.0</td>\n",
       "      <td>2273.0</td>\n",
       "      <td>1599.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     frasier     roz   niles  martin  daphne\n",
       "you  10742.0  2169.0  4113.0  3844.0  2280.0\n",
       "i     9394.0  2057.0  4257.0  3023.0  2250.0\n",
       "the   7868.0  1321.0  3885.0  2678.0  1689.0\n",
       "to    7482.0  1336.0  3530.0  2308.0  1555.0\n",
       "a     6987.0  1282.0  2927.0  2273.0  1599.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for url in urls[1:]: # we did the first one above\n",
    "    d_ep = url_to_lines_dict(url)\n",
    "    for mc in main_characters:\n",
    "        d_char_wc[mc] = Counter(d_char_wc[mc]) + Counter(d_ep[mc])\n",
    "\n",
    "df_char_wc = pd.DataFrame(d_char_wc)\n",
    "df_char_wc.ix[df_char_wc[]]\n",
    "df_char_wc.sort_values(by='frasier', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start computing the \"score\" of each word based on their occurrences, let's first take out the [stop words](https://en.wikipedia.org/wiki/Stop_words). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frasier</th>\n",
       "      <th>roz</th>\n",
       "      <th>niles</th>\n",
       "      <th>martin</th>\n",
       "      <th>daphne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>3748.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>1393.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oh</th>\n",
       "      <td>3563.0</td>\n",
       "      <td>627.0</td>\n",
       "      <td>1461.0</td>\n",
       "      <td>1226.0</td>\n",
       "      <td>964.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>im</th>\n",
       "      <td>2487.0</td>\n",
       "      <td>464.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>2295.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>niles</th>\n",
       "      <td>2167.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>2093.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dad</th>\n",
       "      <td>1731.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>1669.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>507.0</td>\n",
       "      <td>290.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roz</th>\n",
       "      <td>1312.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>1004.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>167.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       frasier    roz   niles  martin  daphne\n",
       "well    3748.0  455.0  1393.0  1120.0   581.0\n",
       "oh      3563.0  627.0  1461.0  1226.0   964.0\n",
       "im      2487.0  464.0  1072.0   709.0   560.0\n",
       "know    2295.0  406.0   654.0   797.0   379.0\n",
       "niles   2167.0  121.0   166.0   384.0   184.0\n",
       "yes     2093.0   83.0   652.0    65.0   238.0\n",
       "dad     1731.0   29.0   621.0    15.0    24.0\n",
       "right   1669.0  210.0   505.0   507.0   290.0\n",
       "roz     1312.0   44.0   146.0    85.0    86.0\n",
       "see     1004.0  124.0   329.0   257.0   167.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(clean_string(sw) for sw in stopwords.words('english'))\n",
    "df_char_wc = df_char_wc.drop(index=stop_words, errors='ignore')\n",
    "## df_char_wc.sort_values(by='frasier', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring the dialogue\n",
    "\n",
    "We're finally ready to compute what are the most distinguishing words of each character. Let's create another dataframe that will store our computed score for each word. First, we square each entry and divide by row sum. That's equivalent to $\\frac{(person\\space says\\space word)^2}{anyone\\space says \\space word}$. \n",
    "\n",
    "What's the motivation of the above? Well, $\\frac{person\\space says\\space word}{anyone\\space says\\space word}$ is how often a person says a word. However, simply having this ratio would result in inflated scores for infrequent words. Thus, multiplying again by $(person\\space says\\space word)$ would take into account the infrequency. See [this illuminating reddit comment](https://www.reddit.com/r/dataisbeautiful/comments/8a4gbr/the_office_characters_most_distinguishing_words_oc/dwwk070?utm_source=share&utm_medium=web2x) for a more detailed explanation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frasier</th>\n",
       "      <th>roz</th>\n",
       "      <th>niles</th>\n",
       "      <th>martin</th>\n",
       "      <th>daphne</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>1.125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>1.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000piece</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100th</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            frasier    roz  niles    martin  daphne\n",
       "1          4.900000  0.400  0.100       NaN     NaN\n",
       "10              NaN  0.250  1.000       NaN    0.25\n",
       "100        2.000000  0.125  1.125       NaN     NaN\n",
       "1000       0.500000  0.500    NaN       NaN     NaN\n",
       "10000      1.333333    NaN    NaN  0.333333     NaN\n",
       "1000piece       NaN    NaN  1.000       NaN     NaN\n",
       "100th           NaN  1.000    NaN       NaN     NaN\n",
       "101             NaN    NaN  0.500  0.500000     NaN\n",
       "1030            NaN    NaN    NaN  1.000000     NaN\n",
       "105             NaN    NaN  1.000       NaN     NaN"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df_score = df_char_wc.apply(np.square).div(df_char_wc.sum(axis=1), axis=0)\n",
    "df_score.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now scale by the following factor: $\\frac{anyone \\space speaks}{person \\space speaks}$. This is to incorporate the fact that some characters simply speak more than other characters -- for example, Frasier naturally has more lines than any other character, as he is not only the main character, but also very verbose by nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['well', 'oh', 'niles', 'yes', 'dad', 'im', 'know', 'roz', 'right',\n",
       "       'see'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_word_count = sum(df_char_wc.sum())\n",
    "for mc in main_characters:\n",
    "    df_score[mc] = df_score[mc] * total_word_count / df_char_wc[mc].sum() \n",
    "df_score.sort_values(by='frasier', ascending=False).head(10).index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's print out the top ten words for the main characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "niles Index(['frasier', 'oh', 'well', 'im', 'maris', 'daphne', 'dad', 'yes', 'going',\n",
      "       'know'],\n",
      "      dtype='object')\n",
      "roz Index(['frasier', 'oh', 'im', 'hey', 'alice', 'know', 'yeah', 'really', 'well',\n",
      "       'get'],\n",
      "      dtype='object')\n",
      "martin Index(['yeah', 'hey', 'oh', 'well', 'know', 'fras', 'eddie', 'got', 'get',\n",
      "       'guys'],\n",
      "      dtype='object')\n",
      "daphne Index(['crane', 'dr', 'oh', 'mum', 'im', 'well', 'like', 'ill', 'mr', 'hes'], dtype='object')\n",
      "frasier Index(['well', 'oh', 'niles', 'yes', 'dad', 'im', 'know', 'roz', 'right',\n",
      "       'see'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for mc in main_characters:\n",
    "    top_10 = df_score.sort_values(by=mc, ascending=False).head(10).index\n",
    "    print(mc, top_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Some of these words are expected: for example, Daphne's \"dr\" \"mr\" \"crane\" makes sense, since she is the only character to refer to the Crane boys as such for a majority of episodes. Furthermore, she is also the only British character, so the appearance of her dreaded \"mum\" is expected. There are also some surprises: I would have thought some form of [\"Oh Dear God\"](https://www.youtube.com/watch?v=jaUy_dlKC0I) would appear for Frasier :-) \n",
    "\n",
    "This was a relatively simple word analysis. In fact, the question of distinguishing dialogue is only a subset of the larger question of determining important words in any document. For in-depth reading, see [this Wikipedia article](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
